---
title: Паралелізм і конкурентність
parent: Python
nav_order: 9
layout: default
---

<!-- @formatter:off -->
# Паралелізм і конкурентність
- TOC
{:toc}
<!-- @formatter:on -->

## Загальне

### Що таке конкурентність і паралелізм?

<hr>

**Конкурентність (concurrency)** — це здатність системи виконувати кілька завдань "одночасно"
(логічно паралельно), але не обов’язково фізично в один момент часу. Завдання можуть
конкурентно виконуватись на одному ядрі за допомогою перемикання контексту.

**Паралелізм (parallelism)** — це реальне одночасне виконання кількох задач на різних
ядрах/процесорах.

### Які є основні підходи до конкурентності в Python?

<hr>

У Python є кілька підходів до конкурентного виконання:

1. **Багатопотоковість (multithreading)**
    * Кожен потік може виконувати завдання.
    * Але через **GIL (Global Interpreter Lock)** лише один потік виконує Python bytecode у
      конкретний
      момент.
    * Ефективно підходить для **I/O-bound** завдань (завантаження даних, робота з мережею), але не
      для CPU-bound.

2. **Багатопроцесність (multiprocessing)**
    * Кожен процес має свій інтерпретатор Python і власний GIL.
    * Реально використовує кілька ядер → підходить для **CPU-bound** задач.

3. **Асинхронність (asyncio)**
    * Заснована на **event loop** (цикл подій) і кооперативній багатозадачності.
    * Ідеально підходить для великої кількості I/O операцій (сотні тисяч запитів).
    * Використовує `await`, щоб віддати керування, поки задача чекає.

| Модуль              | CPU    | Тип багатозадачності | Перемикання    контексту                                            |
|---------------------|--------|----------------------|---------------------------------------------------------------------|
| **asyncio**         | Один   | Cooperative          | Завдання самі вирішують, коли передати управління.                  |
| **threading**       | Один   | Preemptive           | Операційна система вирішує, коли перемикати завдання (поза Python). |
| **multiprocessing** | Багато | Preemptive           | Процеси виконуються одночасно на різних процесорах.                 |

### Що таке I/O-bound та CPU-bound завдання?

<hr>

**CPU-bound завдання** — це завдання, де основне навантаження — обчислення процесора (CPU).

* Виконує багато математичних операцій, обчислень, алгоритмів.
* Мало або взагалі немає очікування на зовнішні ресурси.

Приклади:

* Обчислення простих чисел
* Шифрування / розшифрування
* Машинне навчання
* Обробка зображень або відео

Для cpu-bound завдань у Python використовується **multiprocessing**.

**I/O-bound завдання** — це завдання, де основний час витрачається на очікування зовнішніх ресурсів
(диску, мережі, БД).

* Мало обчислень.
* Багато очікувань (читання/запис файлів, робота з мережею, запити до API).

Приклади:

* Завантаження веб-сторінок
* Читання/запис файлів з диску
* Робота з базами даних

Для I/O-bound завдань у Python добре підходять **threading** (потоки) та **asyncio** (
асинхронність).

### Що таке GIL (Global Interpreter Lock)?

<hr>

**GIL (Global Interpreter Lock)** — це глобальне блокування інтерпретатора у CPython. Це
м’ютекс (lock), який гарантує, що в один момент часу тільки один потік виконує Python-байткод.
Тобто навіть якщо у вас кілька потоків, вони не можуть одночасно виконувати Python-інструкції.

GIL був введений з практичних причин:

1. **Простота реалізації CPython**
    * Багато внутрішніх структур (наприклад, об’єкти, менеджер пам’яті) не є потокобезпечними.
    * GIL дозволяє не робити блокування на кожному об’єкті, що сильно спростило реалізацію
      інтерпретатора.

2. **Автоматичне управління пам’яттю (reference counting)**
    * Python відстежує кількість посилань на об’єкт (reference count).
    * Без GIL доступ до цього лічильника з різних потоків міг би пошкодити пам’ять.

3. **Продуктивність для однопотокових програм**
    * Python історично орієнтувався на скрипти і утиліти.
    * GIL робить однопотокові програми швидшими, бо не треба зайвих блокувань.

Як GIL впливає на багатопоточність?

1. Обмеження паралельності CPU-bound завдань

    * Якщо завдання виконує інтенсивні обчислення (наприклад, обробка великих масивів), то
      багатопоточність у Python не дає приросту швидкості, бо тільки один потік реально виконує код
      у
      будь-який момент.
    * Для CPU-bound завдань треба використовувати multiprocessing (кожен процес має власний GIL).

2. Нормальна робота для I/O-bound завдань
    * Якщо потік очікує на I/O (мережа, диск), GIL відпускається. Інші потоки можуть у цей час
      працювати.
    * Тому для I/O-bound завдань threading або asyncio працюють добре.

### Різниця між потоком і процесом

<hr>

**Потік (thread)** — це одиниця виконання в межах процесу. Усі потоки одного процесу:

* спільно використовують пам’ять і ресурси (heap, файлові дескриптори тощо), але мають власний
  стек і лічильник команд.
* Створюються швидше і «дешевші» за процеси.

**Процес (process)** — окремий екземпляр програми, який виконується незалежно.

* У процеса свої:
    * адресний простір (пам’ять),
    * стек,
    * змінні середовища,
    * дескриптори файлів.
* Процеси не мають спільної пам'яті (для обміну даними потрібні IPC — черги, пайпи, сокети).
* Створення процесів «дорожче», ніж потоків (більше накладних витрат).

### Різниця між синхронним і асинхронним виконанням

<hr>

**Синхронне виконання (synchronous execution)**: код виконується послідовно, крок за кроком. Кожна
операція повинна завершитися, перш ніж почнеться наступна. Якщо одна операція чекає (наприклад,
читає файл чи робить HTTP-запит), то вся програма «зупиняється» на цей час.

**Asynchronous execution (асинхронне виконання):** код не блокується під час очікування (наприклад,
коли йде I/O-операція). Коли задача «чекає», інтерпретатор може перемикається на іншу задачу.
Використовується event loop (цикл подій) для керування виконанням. У Python це реалізується
через `async`/`await` і модуль `asyncio`.

### Різниця між preemptive та cooperative multitasking

<hr>

**Preemptive multitasking (витискальна багатозадачність)**

* ОС або планувальник сам вирішує, коли переключити контекст між задачами.
* Завдання не контролює, коли воно буде «зупинене».
* Процеси/потоки отримують квант часу (наприклад, 10 мс). Після цього ОС може передати CPU іншій
  задачі.
* Якщо одна програма зависне (наприклад, у нескінченному циклі), інші все одно продовжать працювати.

Приклад:

* Windows, Linux, macOS використовують preemptive multitasking.
* У Python модуль `threading` працює саме так — планувальник ОС може зупинити один потік і дати
  процесор іншому.

**Перевага**: стабільність системи, рівномірний розподіл ресурсів.
**Недолік**: більше накладних витрат (контекстні перемикання).

**Cooperative multitasking (кооперативна багатозадачність)**

* Кожне завдання саме повинно «передати управління» іншим.
* Якщо задача «забула» це зробити (наприклад, застрягла у нескінченному циклі), то вона може
  заблокувати всю систему/планувальник.
* Дуже часто використовується в асинхронному програмуванні.

Приклад:

* Ранні версії MacOS і Windows (до Windows 95) використовували cooperative multitasking.
* У Python `asyncio` — це кооперативна багатозадачність: поки ви не напишете `await`, керування не
  передасться іншій корутині.

**Перевага**: простіше реалізація, менше накладних витрат.
**Недолік**: одна «жадібна» задача може блокувати всі інші.

### Що таке перемикання контексту?

<hr>

**Перемикання контексту (context switch)** — це процес, коли операційна система (або планувальник)
призупиняє виконання одного процесу чи потоку і перемикається на інший, зберігаючи весь стан
першого, щоб відновити його пізніше.

**Коли відбувається перемикання контексту?**

Preemptive multitasking (витискальна багатозадачність):

* коли ОС вирішує дати процесор іншому потоку/процесу (наприклад, закінчився квант часу).
* коли потік виконує блокувальну операцію (чекає I/O).

Cooperative multitasking (кооперативна):

* коли завдання саме «передає управління» (наприклад, `await` в asyncio).

**Перемикання контексту** — це дорога операція з точки зору продуктивності:

* треба зберегти стан поточного потоку,
* завантажити стан іншого,
* оновити кеш процесора, TLB, регістри.

Тому занадто часті перемикання можуть знизити ефективність (час йде на перемикання, а не на роботу).

### Коли варто використовувати конкурентність у Python?

<hr>

Використання конкурентності в Python виправдане лише за наявності підтверджених проблем із
продуктивністю.
Далі вибір залежить від типу навантаження:

* I/O-bound → доцільно застосовувати `asyncio` (за наявності підтримки бібліотек) або `threading`/
  `concurrent.futures`, якщо асинхронних аналогів немає.

* CPU-bound → ефективним є лише `multiprocessing`, оскільки GIL блокує паралельність потоків.

**Правило**: `asyncio`, коли можливо; потоки — коли необхідно; процеси — для обчислювально
інтенсивних задач.

## Багатопотоковість (Multithreading)

### Як створити потік у Python?

<hr>

Щоб запустити окремий потік, потрібно створити екземпляр `Thread` і викликати `.start()`.

**Приклад 1: Базове створення потоку**

<!-- @formatter:off -->
```python
import threading
import time

def worker():
    print("Потік запущений")
    time.sleep(2)
    print("Потік завершився")

# створюємо потік
t = threading.Thread(target=worker)

# запускаємо
t.start()

# чекаємо завершення
t.join()
print("Головний потік завершився")
```
<!-- @formatter:on -->

Тут:

* `target=worker` — функція, яку виконує потік.
* `start()` — запускає виконання у новому потоці.
* `join()` — блокує головний потік, доки `t` не завершиться.

**Приклад 2: Потік з аргументами**

<!-- @formatter:off -->
```python
import threading
import time

def worker_with_args(name, delay):
    print(f"Потік {name} стартує")
    time.sleep(delay)
    print(f"Потік {name} завершився")

t1 = threading.Thread(target=worker_with_args, args=("A", 2))
t2 = threading.Thread(target=worker_with_args, args=("B", 3))

t1.start()
t2.start()

t1.join()
t2.join()
print("Усі потоки завершені")
```
<!-- @formatter:on -->


**Приклад 3: Створення власного класу потоку**

<!-- @formatter:off -->
```python
import threading
import time

class MyThread(threading.Thread):
    def __init__(self, name, delay):
        super().__init__()
        self.name = name
        self.delay = delay

    def run(self):
        print(f"Потік {self.name} стартує")
        time.sleep(self.delay)
        print(f"Потік {self.name} завершився")

t = MyThread("Custom", 2)
t.start()
t.join()

```
<!-- @formatter:on -->

### Що таке daemon thread?

<hr>

**Daemon thread (демон-потік)** у Python — це потік, який працює у фоновому режимі та не блокує
завершення програми. Як тільки всі нормальні (non-daemon) потоки завершились, Python автоматично
завершує усі потоки-демони, навіть якщо вони ще виконуються.

Daemon-потоки використовують для фонових задач, які не критично завершити до кінця (наприклад,
логування, моніторинг, оновлення кешу).

**Приклад**

<!-- @formatter:off -->
```python
import threading
import time

def background_task():
    while True:
        print("Фоновий потік працює...")
        time.sleep(1)

# створюємо потік-демон
t = threading.Thread(target=background_task, daemon=True)
t.start()

print("Головний потік завершується")
```
<!-- @formatter:on -->

У цьому прикладі після завершення головного потоку програма закриється, і фоновий потік буде
зупинений.

### Для чого використовується `join()`?

<hr>

Метод `join()` використовується для того, щоб заблокувати виконання потоку, який викликає `join()`,
доки вказаний потік (звичайний потік або daemon) не завершить роботу.

Іншими словами:

* `start()` запускає новий потік.
* `join()` каже: "Почекай тут, доки цей потік закінчить виконання".

Метод `join()` потрібен для

* **синхронізації потоків** — коли потрібно дочекатися результату потоку перед подальшими діями;
* **контролю завершення програми** — щоб впевнитися, що всі важливі потоки завершилися (наприклад,
  збереження файлу чи закриття підключення).
* **відсутність race condition** — дозволяє уникнути ситуацій, коли головний потік закривається
  раніше, ніж завершився робочий.

**Приклад**

<!-- @formatter:off -->
```python
import threading
import time

def worker():
    print("Потік почав роботу")
    time.sleep(2)
    print("Потік завершив роботу")

t = threading.Thread(target=worker)
t.start()

print("Очікуємо завершення потоку...")
t.join()
print("Головний потік продовжив виконання")
```
<!-- @formatter:on -->

Результат:

* Потік запускається.
* Головний потік зупиняється на `join()`.
* Коли потік закінчує роботу — виконання йде далі.

Метод `join()` також приймає параметр `timeout` (у секундах).
Це означає, що головний потік чекатиме не довше ніж `timeout` секунд, навіть якщо потік ще працює.

```python
t.join(timeout=1)  # чекаємо максимум 1 секунду
```

### Що таке пул потоків (thread pool)?

<hr>

`Пул потоків (thread pool)` — це механізм, де створюється обмежена кількість потоків, які
багаторазово використовуються для виконання завдань. Замість того, щоб створювати новий потік
для кожної задачі (що дорого по ресурсах), пул управляє колекцією потоків і розподіляє між ними
роботу.

`ThreadPoolExecutor` — це клас із модуля `concurrent.futures`, який надає високорівневий API для
роботи з пулом потоків. Він дозволяє:

* створювати пул з обмеженою кількістю потоків (`max_workers`),
* відправляти задачі у виконання,
* отримувати результати у зручній формі через `Future`.

**Основні методи**

* `submit(fn, *args, **kwargs)`
    * відправляє функцію `fn` у пул;
    * повертає об’єкт `Future`, через який можна отримати результат.
* `map(fn, iterable)`
    * аналог вбудованої `map()`, але виконує виклики паралельно у пулі;
    * повертає ітератор з результатами у тому ж порядку, що й вхідні дані.
* `shutdown(wait=True)`
    * завершує пул, чекає на всі задачі (якщо `wait=True`).
    * зазвичай викликається автоматично у контекстному менеджері `with`.

**Приклад 1: `submit()`**

<!-- @formatter:off -->
```python
from concurrent.futures import ThreadPoolExecutor
import time

def task(n):
    print(f"Початок задачі {n}")
    time.sleep(2)
    return n * n

with ThreadPoolExecutor(max_workers=3) as executor:
    futures = [executor.submit(task, i) for i in range(5)]

    for f in futures:
        print("Результат:", f.result())
```
<!-- @formatter:on -->

Тут:

* максимум 3 задачі виконуються паралельно;
* `f.result()` чекає, поки завершиться конкретна задача.

**Приклад 2: `map()`**

```python
with ThreadPoolExecutor(max_workers=3) as executor:
    results = executor.map(task, range(5))
    for res in results:
        print("Результат:", res)
```

`map()` зручний, якщо треба просто прогнати функцію по набору даних і зібрати результати.

Після виходу з блоку with `ThreadPoolExecutor` виконує `join()` для всіх потоків у пулі.
Рекомендується
завжди використовувати його як контекстний менеджер, щоб не забути викликати `join()`.

### Що таке race conditions?

<hr>

**Race condition (стан гонитви)** — це ситуація, коли результат роботи програми залежить від порядку
виконання потоків, і через це виникає некоректна або непередбачувана поведінка. Тобто два чи
більше потоки одночасно отримують доступ до спільного ресурсу (змінна, файл, БД) і
змінюють його без синхронізації.

Простий приклад

<!-- @formatter:off -->
```python
import threading

counter = 0

def increment():
    global counter
    for _ in range(100000):
        counter += 1  # неатомарна операція

threads = [threading.Thread(target=increment) for _ in range(2)]

for t in threads: t.start()
for t in threads: t.join()

print("Очікувано:", 200000)
print("Фактично:", counter)
```
<!-- @formatter:on -->

В ідеалі результат має бути 200000, але через race condition буде менше.
Причина: `counter += 1` виконується у кілька кроків (читання → збільшення → запис), і потоки можуть
"перебивати" одне одного.

### Які є шляхи запобігання race conditions?

<hr>

Race conditions запобігають через механізми синхронізації (`Lock`, `RLock`, `Semaphore`,
`Condition`),
використання thread-safe структур даних, черг повідомлень або повну відмову від спільного стану. Для
CPU-bound задач часто краще перейти на multiprocessing, щоб уникнути проблем із GIL та гонками.

1. **Використання блокувань (`Locks`, `RLocks`)**
    * `threading.Lock()` або `threading.RLock()` (reentrant lock).
    * Гарантують, що тільки один потік може виконати критичну секцію одночасно.

    <!-- @formatter:off -->
    ```python
    lock = threading.Lock()
    with lock:
        counter += 1
    ```
   <!-- @formatter:on -->

2. **Семафори (`threading.Semaphore`)**
    * Дозволяють обмежити кількість потоків, що одночасно виконують певну дію.
    * Наприклад, дозволити максимум 3 потоки, які працюють з БД.

3. **Події (`threading.Event`) та умови (`threading.Condition`)**
    * Використовуються для координації роботи потоків, щоб уникнути "перетинів" доступу.

4. **`Thread`-safe структури даних**
    * Наприклад, `queue.Queue`, `collections.deque` (з `maxlen`) у багатопоточному режимі.
    * Вони вже всередині реалізовані з блокуваннями.

5. **Використання атомарних операцій**
    * Наприклад, у модулі `multiprocessing` є `Value` і `Array`, які підтримують блокування.
    * У Python немає повністю атомарних арифметичних операцій через GIL, але GIL захищає деякі
      прості дії (наприклад, інкремент лічильника у `queue`).

6. **Дизайн без спільного стану**
    * Найбільш надійний спосіб — не ділитися змінними між потоками.
    * Використовувати черги для передачі повідомлень (message passing).

7. **Перехід на багатопроцесність (`multiprocessing`)**
    * Кожен процес має власну пам’ять → менше ризиків для race conditions.
    * Але тоді потрібні механізми обміну даними (queues, pipes).

### Що таке mutex?

<hr>

`Mutex (mutual exclusion object)` — це примітив синхронізації, який гарантує, що лише один потік у
певний момент часу може виконувати критичну секцію коду. Іншими словами, mutex — це "замок" для
доступу до спільного ресурсу.

Як працює:

1. Потік намагається отримати (acquire) mutex.
2. Якщо mutex вільний → потік заходить у критичну секцію.
3. Якщо mutex зайнятий → потік блокується, доки mutex не буде звільнений.
4. Коли потік завершує роботу з ресурсом, він звільняє (release) mutex.

У Python mutex реалізується як `threading.Lock()`.

Приклад

<!-- @formatter:off -->
```python
import threading

lock = threading.Lock()
counter = 0

def increment():
    global counter
    for _ in range(100000):
        with lock:   # захоплення і звільнення відбувається автоматично
            counter += 1

threads = [threading.Thread(target=increment) for _ in range(5)]

for t in threads: t.start()
for t in threads: t.join()

print("Результат:", counter)
```
<!-- @formatter:on -->

Без lock тут буде race condition, а з lock результат гарантовано правильний.

### Що таке deadlock?

<hr>

**Deadlock (взаємне блокування)** — це ситуація, коли два або більше потоки назавжди чекають один на
одного, і жоден із них не може продовжити виконання.

Простими словами:

* Потік А утримує ресурс 1 і чекає ресурс 2.
* Потік B утримує ресурс 2 і чекає ресурс 1.
* Результат → обидва заблоковані назавжди.

Приклад

<!-- @formatter:off -->
```python
import threading
import time

lock1 = threading.Lock()
lock2 = threading.Lock()

def task1():
    with lock1:
        print("task1 захопив lock1")
        time.sleep(1)
        with lock2:
            print("task1 захопив lock2")

def task2():
    with lock2:
        print("task2 захопив lock2")
        time.sleep(1)
        with lock1:
            print("task2 захопив lock1")

t1 = threading.Thread(target=task1)
t2 = threading.Thread(target=task2)

t1.start()
t2.start()

t1.join()
t2.join()
```
<!-- @formatter:on -->

**Як уникати deadlock:**

1. **Єдиний порядок захоплення ресурсів**
    * Домовитися, що всі потоки завжди захоплюють блокування в однаковій послідовності (наприклад,
      спочатку `lock1`, потім `lock2`).

2. **Таймаути при блокуванні**
    * Використовувати `lock.acquire(timeout=...)`, щоб уникати нескінченного очікування.

3. **Використання вищорівневих примітивів**
    * Наприклад, `queue.Queue` замість ручних блокувань.

4. **Уникати надлишкових блокувань**
    * Мінімізувати розмір критичних секцій.

### Різниця між deadlock, livelock і starvation

<hr>

Коротка відповідь:

* **Deadlock**: повна зупинка потоків, вони чекають один одного.
* **Livelock**: потоки активні, але не роблять прогресу.
* **Starvation**: потік не отримує ресурс через пріоритети або сильну конкуренцію.

**1. Deadlock (взаємне блокування)**

Що відбувається:

* Два або більше потоків чекають ресурси один одного і заблоковані назавжди.
* Жоден потік не може продовжити виконання.

Приклад:

* Потік A захопив lock1, чекає lock2.
* Потік B захопив lock2, чекає lock1.
* Обидва чекають один одного → зависають.

Візуальна аналогія: дві людини блокують двері в кімнаті одна для одної, і обидві не можуть вийти.

**2. Livelock (живий конфлікт)**

Що відбувається:

* Потоки активно змінюють свій стан у відповідь один одному, але не роблять прогресу.
* На відміну від deadlock, потоки не заблоковані, вони постійно “працюють”, але завдання не
  завершується.

Приклад:

* Два потоки намагаються ввійти в критичну секцію і відступають, щоб дати іншому пройти.
* Вони постійно відступають і намагаються знову → ніякого прогресу немає.

Візуальна аналогія: двоє людей на вузькому проході постійно відступають один від одного, але ніхто
не проходить.

**3. Starvation (голодування)**

Що відбувається:

* Поток або процес тривалий час не отримує доступ до ресурсу, хоча система працює.
* Причина — інші потоки постійно отримують пріоритет.

Приклад:

* У системі з пріоритетами низькопріоритетний потік ніколи не отримує CPU, бо високопріоритетні
  потоки постійно займають його.

Візуальна аналогія: в черзі в магазині низькопріоритетна людина постійно пропускає тих, хто має
високий пріоритет, і ніколи не обслуговується.

### Що таке RLock?

<hr>

**RLock (reentrant lock)** — це перевикористовуваний блокувальний об’єкт у Python.
Він дозволяє потоку, який вже захопив блокування, захоплювати його повторно без блокування самого
себе.

Іншими словами: звичайний `Lock` не дозволяє одному потоку повторно заходити в критичну секцію, а
`RLock` — дозволяє.

Навіщо потрібен:

1. Коли у функції, яка використовує lock, викликається інша функція, яка теж намагається захопити
   той самий lock.
2. Щоб уникнути самоблокування потоку (self-deadlock).

Приклад

<!-- @formatter:off -->
```python
import threading

lock = threading.RLock()

def recursive_function(n):
    with lock:
        print(f"Потік захопив RLock, n={n}")
        if n > 0:
            recursive_function(n-1)

t = threading.Thread(target=recursive_function, args=(3,))
t.start()
t.join()
```
<!-- @formatter:on -->

У цьому прикладі:

* Потік захоплює `RLock` на рівні `n=3`, потім знову на рівні `n=2` і так далі.
* Звичайний `Lock` заблокував би потік при повторному захопленні → self-deadlock.
* `RLock` дозволяє потоку заходити повторно без проблем.

### Що таке Semaphore?

<hr>

**Semaphore (семафор)** — це примітив синхронізації, який обмежує кількість потоків, які можуть
одночасно виконувати певну дію або використовувати ресурс.

У Python реалізується через `threading.Semaphore(value=N)`, де `N` — максимальна кількість потоків,
які
можуть увійти в критичну секцію одночасно.

Потоки, що перевищують `N`, блокуються, доки місце не звільниться.

Навіщо потрібен:

* Контролювати доступ до обмежених ресурсів (наприклад, пул з’єднань до бази даних).
* Організувати обмежену кількість одночасних задач у багатопоточній програмі.
* Уникнути race conditions у певних сценаріях.

<!-- @formatter:off -->
```python
import threading
import time

sem = threading.Semaphore(2)  # максимум 2 потоки одночасно

def worker(n):
    print(f"Потік {n} чекає доступу")
    with sem:
        print(f"Потік {n} увійшов")
        time.sleep(2)
        print(f"Потік {n} вийшов")

threads = [threading.Thread(target=worker, args=(i,)) for i in range(5)]

for t in threads: t.start()
for t in threads: t.join()
```
<!-- @formatter:on -->

У будь-який момент максимум 2 потоки знаходяться всередині блоку `with sem`. Інші потоки чекають,
поки місце звільниться.

### Що таке barrier?

<hr>

**Barrier (бар’єр)** — це примітив синхронізації у Python (`threading.Barrier`), який дозволяє групі
потоків чекати один одного, поки всі не дійдуть до певної точки виконання, після чого вони всі
продовжують роботу одночасно.

* Використовується для синхронізації кількох потоків у певному пункті програми.
* Зручно, коли потрібно, щоб усі потоки завершили певний етап, перш ніж рухатися далі.

Приклад

<!-- @formatter:off -->
```python
import threading
import time

barrier = threading.Barrier(3)  # чекаємо 3 потоки

def worker(n):
    print(f"Потік {n} стартує")
    time.sleep(n)  # робимо різну роботу
    print(f"Потік {n} чекає на бар’єрі")
    barrier.wait()
    print(f"Потік {n} пройшов бар’єр")

threads = [threading.Thread(target=worker, args=(i,)) for i in range(3)]

for t in threads: t.start()
for t in threads: t.join()
```
<!-- @formatter:on -->

Що відбувається:

* Потоки 0, 1, 2 працюють різну кількість часу.
* Коли потік доходить до `barrier.wait()`, він чекає інші потоки.
* Коли всі три потоки досягли бар’єру, вони одночасно продовжують виконання.

## Багатопроцесність (Multiprocessing)

### Як multiprocessing відрізняється від multithreading?

<hr>

1. **Модель виконання**

   **Multithreading** – кілька потоків працюють в межах одного процесу, розділяючи спільний простір
   пам’яті та ресурси. Потоки легші, їх створення та перемикання контексту менш витратне.

   **Multiprocessing** – створюються окремі процеси, кожен зі своїм інтерпретатором Python та
   власним
   простором пам’яті. Процеси ізольовані один від одного, взаємодіють через (Inter-Process
   Communication) (черги, пайпи, менеджери).

2. **GIL (Global Interpreter Lock)**

    * У Python потоки обмежені GIL: одночасно тільки один потік може виконувати байт-код Python. Це
      робить
      multithreading неефективним для CPU-bound завдань, але він добре підходить для I/O-bound задач
      (мережа, файлові операції, робота з API).

    * У multiprocessing кожен процес має свій інтерпретатор і власний GIL, тому кілька процесів
      можуть
      реально використовувати кілька ядер процесора паралельно. Це оптимальний вибір для CPU-bound
      завдань.

3. **Витрати ресурсів**

    * Потоки: легкі, швидкі у створенні, але можуть блокувати один одного через GIL і потребують
      синхронізації (Lock, Semaphore, Event) для уникнення race conditions.

    * Процеси: важчі, оскільки копіюють пам’ять та запускають окремий інтерпретатор. IPC має більший
      overhead, але це дає кращу ізоляцію й стабільність — збій в одному процесі не валить увесь
      додаток.

4. **Використання на практиці**

    * Multithreading: ефективний для I/O-bound задач — веб-сервери, скрейпінг, робота з сокетами,
      очікування відповіді від зовнішніх систем.

    * Multiprocessing: ефективний для CPU-bound задач — обробка зображень, машинне навчання,
      чисельні
      розрахунки.

### Що таке Inter-Process Communication?

<hr>

**IPC (Inter-Process Communication)** — це механізми, які дозволяють окремим процесам обмінюватися
даними між собою, адже кожен процес має власний простір пам’яті і напряму "поділитися змінною" не
може.

В ОС існує кілька основних способів IPC:

* **Черги (Queue)** — процеси обмінюються повідомленнями у форматі FIFO.
* **Канали/пайпи (Pipes)** — передача потоків даних між процесами.
* **Shared memory** — виділення спільного сегмента пам’яті, до якого мають доступ кілька процесів.
* **Сокети** — універсальний спосіб взаємодії, який працює як у межах однієї машини, так і через
  мережу.
* **Signals**, **Events**, **Semaphores** — використовуються для синхронізації дій між процесами.

У Python (через модуль `multiprocessing`) найчастіше застосовують Queue та Pipe, бо вони прості у
використанні й приховують низькорівневі деталі синхронізації.

### Як створити процес?

<hr>

1. Через клас `multiprocessing.Process` (базовий спосіб)
    * Створюємо об’єкт `Process`, передаємо в нього функцію (`target`) і аргументи.
    * Викликаємо `.start()`, щоб запустити процес, і `.join()`, щоб дочекатися завершення.

    <!-- @formatter:off -->
    ```python
    from multiprocessing import Process
    
    def f(name):
        print('hello', name)
    
    if __name__ == '__main__':
        p = Process(target=f, args=('bob',))
        p.start()
        p.join()
    ```
    <!-- @formatter:on -->

2. Наслідування від `multiprocessing.Process`
    * Створюємо власний клас, що успадковується від `Process`.
    * Перевизначаємо метод `run()`, який виконується у новому процесі.

   <!-- @formatter:off -->
   ```python
   from multiprocessing import Process
   
   class MyProcess(Process):
       def run(self):
           print("Це мій власний процес")
   
   if __name__ == "__main__":
       p = MyProcess()
       p.start()
       p.join()
   ```
   <!-- @formatter:on -->

3. Через `concurrent.futures.ProcessPoolExecutor`
    * Більш високорівневий API для керування пулом процесів.
    * Дозволяє легко запускати багато задач паралельно.

   <!-- @formatter:off -->
   ```python
   from concurrent.futures import ProcessPoolExecutor
   
   def square(x):
       return x * x
   
   if __name__ == "__main__":
       with ProcessPoolExecutor() as executor:
           results = list(executor.map(square, [1, 2, 3, 4]))
           print(results)
   ```
   <!-- @formatter:on -->

4. За допомогою `multiprocessing.Pool`
    * Простіший спосіб паралельно виконати одну функцію над набором даних.

   <!-- @formatter:off -->
   ```python
   from multiprocessing import Pool
   
   def square(x):
       return x * x
   
   if __name__ == "__main__":
       with Pool(4) as pool:
           results = pool.map(square, [1, 2, 3, 4])
           print(results)
   ```
   <!-- @formatter:on -->

## Асинхронність (Async)

### Що таке event loop?

<hr>

**Event loop (цикл подій)** — це механізм у `asyncio`, який керує виконанням асинхронних завдань 
(корутин).

* Він постійно чекає на події (наприклад, завершення I/O, таймерів, сигналів).
* Коли подія відбувається, event loop запускає або відновлює відповідну корутину.
* Це дозволяє виконувати багато завдань у кооперативній багатозадачності (корутини самі віддають
  управління через `await`).

**Як працює event loop (спрощено)**

1. Створюються корутини (функції з `async def`).
2. Event loop отримує їх у чергу.
3. Коли корутина виконує `await` (наприклад, `await asyncio.sleep(1)`), вона віддає управління циклу
   подій.
4. Event loop тим часом перемикається на інші завдання.
5. Коли очікувана подія завершується (I/O, таймер), event loop «будить» корутину і продовжує її з
   того місця.

### Як запустити event loop?

<hr>

Є два основних способи запуску event loop:

1. Сучасний спосіб (Python 3.7+) – за допомогою `asyncio.run()`. Це найзручніший і 
   рекомендований варіант. Ми просто передаємо в нього корутину, і він:
    * створює цикл,
    * запускає його,
    * закриває цикл після завершення.

     <!-- @formatter:off -->
     ```python
     import asyncio
         
     async def main():
         print("Привіт")
         await asyncio.sleep(1)
         print("Світ")
         
     asyncio.run(main())
     ```
     <!-- @formatter:on -->

2. Низькорівневий спосіб (старіший, до 3.7 або коли потрібен ручний контроль) – через
   `get_event_loop()` і `run_until_complete()`.

   <!-- @formatter:off -->
   ```python
   import asyncio
   
   async def main():
       print("Hello")
       await asyncio.sleep(1)
       print("World")
   
   loop = asyncio.get_event_loop()
   loop.run_until_complete(main())
   loop.close()
   ```
   <!-- @formatter:on -->

### У чому різниця між `asyncio.run()` та `asyncio.gather()`?

<hr>

1. `asyncio.run(coro)` — це точка входу в асинхронний світ.
    * Використовується для запуску однієї корутини з синхронного коду.
    * Під капотом створює новий event loop, виконує корутину і закриває цикл після завершення.
    * Застосовується лише один раз у програмі (зазвичай у `main`).

   <!-- @formatter:off -->
   ```python
   import asyncio
   
   async def main():
       print("Hello")
       await asyncio.sleep(1)
       print("World")
   
   asyncio.run(main())  # запускає цикл подій
   ```
   <!-- @formatter:on -->

2. `asyncio.gather(*coroutines)` — це спосіб всередині існуючого event loop запустити кілька
   корутин паралельно.
    * Повертає результат усіх переданих задач.
    * Не створює новий event loop, а працює у вже запущеному.

   <!-- @formatter:on -->
   ```python
   import asyncio
   
   async def worker(n):
       await asyncio.sleep(1)
       return f"Done {n}"
   
   async def main():
       results = await asyncio.gather(
           worker(1),
           worker(2),
           worker(3)
       )
       print(results)
   
   asyncio.run(main())  # тут запускаємо цикл
   ```
   <!-- @formatter:on -->

   У цьому прикладі `gather` виконує три задачі конкурентно в одному циклі.

### Що таке корутина (coroutine)?

<hr>

**Корутина (coroutine)** — це спеціальна функція, яка може призупиняти своє виконання (`await`) і
повертати управління викликачеві (наприклад, event loop), а потім продовжувати роботу з того ж
місця.

У Python корутини створюються через ключове слово `async def`.

Особливості:

* Виклик `async def`-функції не запускає її одразу, а повертає корутину-об’єкт.
* Для запуску потрібен event loop (`await` або `asyncio.run()`).
* Всередині корутини можна використовувати `await` для очікування іншої корутини або асинхронної
  операції.
* Вони реалізують кооперативну багатозадачність: корутина сама вирішує, коли віддати управління 
  (`await`).

### Різниця між корутиною і потоком

<hr>

**Потоки (Threads)** — це одиниці виконання всередині процесу.

* Виконуються «паралельно» (але у CPython — тільки один потік виконує байткод одночасно через GIL).
* Планування потоків робить ОС (preemptive multitasking).
* Підходять для I/O-bound завдань (мережа, файли).
* Використовують реальні системні ресурси ОС → більше накладних витрат.
* У Python створюються через `threading.Thread` або `ThreadPoolExecutor`.

**Корутини (Coroutines)** — функції, які можуть призупиняти і відновлювати виконання (`await`).

* Виконуються в одному потоці під управлінням event loop (`asyncio`).
* Планування робить сам інтерпретатор (cooperative multitasking).
* Добре підходять для I/O-bound завдань з великою кількістю одночасних операцій.
* Легкі (lightweight): тисячі корутин можуть працювати всередині одного потоку.
* У Python створюються через `async def`.

### За що відповідають ключові слова `async`/`await`?

<hr>

`async` — це ключове слово, яке використовується для оголошення асинхронної функції (корутини).
При виклику `async def`-функції вона не виконується відразу, а повертає об’єкт-корутину. Для
запуску потрібен event loop (через `await` або `asyncio.run`).

Приклад:
<!-- @formatter:off -->
```python
async def fetch_data():
    return "some data"

result = fetch_data()  # Це ще не результат, а корутина!
print(result)  # <coroutine object fetch_data at ...>
```
<!-- @formatter:on -->

`await` — це ключове слово, яке використовується всередині `async`-функцій. Каже: «Призупини цю
корутину, дочекайся результату іншої асинхронної операції, а потім продовжуй». Працює тільки з
awaitable-об’єктами (корутини, `asyncio.Task`, `asyncio.Future`). У цей час event loop може
переключитися на інші задачі.

Приклад:
<!-- @formatter:off -->
```python
import asyncio

async def fetch_data():
    print("Fetching...")
    await asyncio.sleep(2)  # не блокує, віддає управління event loop
    return "some data"

async def main():
    data = await fetch_data()  # чекаємо результат
    print("Got:", data)

asyncio.run(main())
```
<!-- @formatter:on -->

### Які дві реалізації event loop входять в asyncio?

<hr>

В `asyncio` є дві основні реалізації event loop:

1. `SelectorEventLoop`
    * Це стандартна реалізація, яка базується на системних примітивах для неблокуючого I/O:
        * на Linux і BSD — epoll / kqueue,
        * на Windows — select.
    * Використовується за замовчуванням на всіх платформах, крім сучасних Windows.
    * Добре працює як з мережевими сокетами, так і з файловими дескрипторами.

2. `ProactorEventLoop`
    * Реалізація, специфічна для Windows, яка використовує Windows I/O Completion Ports (IOCP).
    * Краще працює з асинхронними сокетами й підходить для high-performance сценаріїв.
    * Починаючи з Python 3.8, на Windows за замовчуванням використовується саме `ProactorEventLoop`.

### Що таке асинхронний генератор?

<hr>

**Асинхронний генератор** — це генератор, який дозволяє асинхронно ітеруватись по значеннях. Він
поєднує в собі концепції:

* `async def` (корутина),
* і `yield` (генератор).

Оголошується він як `async def`, але замість `return` використовує `yield`.

Приклад:

<!-- @formatter:off -->
```python
import asyncio

async def async_generator():
    for i in range(3):
        await asyncio.sleep(1)  # асинхронна пауза
        yield i  # віддаємо значення поступово
        
async def main():
    async for value in async_generator():
        print(value)

asyncio.run(main())
```
<!-- @formatter:on -->

Ключові моменти:

* На відміну від звичайного генератора, асинхронний може `await`-ити всередині (наприклад, робити
  мережеві запити або чекати таймер).
* Щоб перебрати його значення, треба використовувати `async for`, а не звичайний `for`.
* Асинхронні генератори з’явилися у Python 3.6 (PEP 525).

Навіщо вони потрібні?

* Для потокового отримання даних з мережі (наприклад, стрімінг API).
* Для поступового читання великих файлів чи асинхронних запитів до БД.
* Для сценаріїв, де дані приходять поступово й немає сенсу чекати на всі одразу.

### Що таке асинхронний ітератор?

<hr>

**Асинхронний ітератор** — це об’єкт, який реалізує асинхронний протокол ітерації, тобто має методи:

* `__aiter__(self)` → повертає сам ітератор,
* `__anext__(self)` → повертає наступне значення у вигляді корутини.

Ключова відмінність від звичайного ітератора: `__anext__` не повертає значення напряму, а повертає
`awaitable` (обіцянку значення), тому для роботи з ним потрібен `async for`.

**Приклад асинхронного ітератора:**

<!-- @formatter:off -->
```python
import asyncio

class AsyncCounter:
    def __init__(self, limit):
        self.i = 0
        self.limit = limit

    def __aiter__(self):
        return self

    async def __anext__(self):
        if self.i < self.limit:
            await asyncio.sleep(1)  # асинхронна операція
            self.i += 1
            return self.i
        else:
            raise StopAsyncIteration

async def main():
    async for num in AsyncCounter(3):
        print(num)

asyncio.run(main())
```
<!-- @formatter:on -->

Ключові моменти:

* Асинхронні ітератори дозволяють робити паузи (`await`) між кроками ітерації.
* Використовуються тоді, коли дані приходять поступово (наприклад, із сокета чи API).
* Для перебору завжди потрібен `async for`, бо кожен крок — це асинхронний виклик.

Різниця з асинхронним генератором

* Асинхронний генератор (`async def ... yield`) — це зручний синтаксичний цукор для створення
  асинхронних ітераторів.
* Асинхронний ітератор — більш низькорівневий, треба самому писати `__aiter__` і `__anext__`.

### Що таке async for?

<hr>

`async for` — це конструкція, яка дозволяє асинхронно перебирати значення з асинхронних ітераторів
чи асинхронних генераторів. На відміну від звичайного `for`, вона викликає метод `__anext__()` і
чекає на результат через `await`.

Приклад із асинхронним генератором

<!-- @formatter:off -->
```python
import asyncio

async def async_generator():
    for i in range(3):
        await asyncio.sleep(1)  # імітація асинхронної операції
        yield i

async def main():
    async for value in async_generator():
        print(value)

asyncio.run(main())
```
<!-- @formatter:on -->

Результат: числа 0, 1, 2 виводяться з паузою в 1 секунду.

Ключові моменти для співбесіди

* `async for` використовується замість звичайного `for`, коли ітератор або генератор містить
  асинхронні операції.
* Всередині він викликає `await` на кожному кроці ітерації.
* Працює лише всередині `async def`.

### Що таке асинхронний контекстний менеджер (async with)?

<hr>

В Python `async with` використовується для роботи з асинхронними контекстними менеджерами.
Це об’єкти, які реалізують асинхронні версії методів:

* `__aenter__(self)` — викликається при вході в контекст (`async with`). Повертає awaitable, яке
  треба
  виконати.
* `__aexit__(self, exc_type, exc, tb)` — викликається при виході з контексту. Також повертає
  awaitable.

Тобто, це асинхронний аналог звичайного `with`, який дозволяє коректно відкривати та закривати
ресурси, що потребують асинхронної роботи (наприклад, мережеві з’єднання).

Приклад простого асинхронного контекстного менеджера

<!-- @formatter:off -->
```python
import asyncio

class AsyncContext:
    async def __aenter__(self):
        print("Входимо в контекст")
        await asyncio.sleep(1)  # асинхронна ініціалізація
        return "Ресурс готовий"

    async def __aexit__(self, exc_type, exc, tb):
        await asyncio.sleep(1)  # асинхронне завершення
        print("Виходимо з контексту")

async def main():
    async with AsyncContext() as resource:
        print(resource)

asyncio.run(main())
```
<!-- @formatter:on -->

Ключові моменти для співбесіди

* `async with` потрібен тоді, коли відкриття або закриття ресурсу є асинхронними операціями.
* Це особливо корисно при роботі з:
    * асинхронними мережевими клієнтами (наприклад, `aiohttp.ClientSession`),
    * асинхронними транзакціями в базах даних,
    * асинхронними lock/semaphore (`asyncio.Lock`).

* Як і у звичайному `with`, якщо всередині блоку виникне виняток, `__aexit__` все одно виконається і
  коректно звільнить ресурси.

### Що таке async.gather()?

<hr>

`asyncio.gather()` — це утиліта з модуля `asyncio`, яка дозволяє одночасно виконати кілька
асинхронних задач в одному event loop та зібрати їх результати.

Як працює

* Приймає кілька корутин (або `Task`-ів).
* Запускає їх конкурентно (одночасно, але всередині одного потоку).
* Повертає одну корутину, яка завершується, коли всі передані задачі виконані.
* Результат — список (`tuple`) значень у тому ж порядку, в якому задачі були передані.

Приклад

<!-- @formatter:off -->
```python
import asyncio

async def worker(n):
    await asyncio.sleep(n)
    return f"Завдання {n} виконане"

async def main():
    results = await asyncio.gather(
        worker(1),
        worker(2),
        worker(3),
    )
    print(results)

asyncio.run(main())
```
<!-- @formatter:on -->

Виведе приблизно:

```python
['Завдання 1 виконане', 'Завдання 2 виконане', 'Завдання 3 виконане']
```

Усі три завдання виконуються паралельно в одному event loop, хоча в коді ми чекаємо на результат
лише один раз.

Ключові моменти

* `asyncio.gather()` — це спосіб запустити кілька корутин паралельно.
* Порядок результатів зберігається відповідно до аргументів, навіть якщо виконання відбувалось у
  різний час.
* Якщо якась корутина під час виконання згенерує виняток, `gather()` перекине його. Можна
  використати `return_exceptions=True`, щоб зібрати винятки як результати, а не падати.

### Що таке `ExceptionGroup`?

<hr>

`ExceptionGroup` — це новий тип винятків, який з’явився в Python 3.11. Він використовується для
групування кількох винятків в один об’єкт. Це корисно, коли одночасно можуть виникати кілька
помилок (наприклад, у паралельних задачах або при роботі з асинхронними потоками), і потрібно
обробити їх централізовано.

Приклад використання в асинхронному контексті:

<!-- @formatter:off -->
```python
>>> import asyncio

>>> async def coro_a():
...     await asyncio.sleep(1)
...     raise ValueError("Error in coro A")
...

>>> async def coro_b():
...     await asyncio.sleep(2)
...     raise TypeError("Error in coro B")
...

>>> async def coro_c():
...     await asyncio.sleep(0.5)
...     raise IndexError("Error in coro C")
...

>>> async def main():
...     results = await asyncio.gather(
...         coro_a(),
...         coro_b(),
...         coro_c(),
...         return_exceptions=True
...     )
...     exceptions = [e for e in results if isinstance(e, Exception)]
...     if exceptions:
...         raise ExceptionGroup("Errors", exceptions)
```
<!-- @formatter:on -->
